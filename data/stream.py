import random, torch

from transformers import PreTrainedTokenizer

from .utils import rand_bool, load_video, load_frames



class StreamMixIn(torch.utils.data.Dataset):
    def __init__(
        self,
        is_training: bool,
        system_prompt: str,
        augmentation: bool,
        max_num_frames: int,
        interleave: bool,# shih-po's edition
        tokenizer: PreTrainedTokenizer,
        **kwargs,
    ):
        super().__init__()
        self.is_training = is_training
        self.system_prompt = system_prompt
        self.augmentation = augmentation
        self.tokenizer = tokenizer
        self.max_num_frames = max_num_frames
        self.interleave = interleave
        assert system_prompt is not None, "Please add a system prompt"

    # NOTE: this augmentation is to reduce the text dependency
    def augment(self, conversation):
        if not self.augmentation or not self.is_training:
            return conversation
        assistant_messages = [
            (i, message)
            for i, message in enumerate(conversation)
            if message["role"] == "assistant" and message.get("learn", False)
        ]
        if len(assistant_messages) <= 1:
            return conversation
        i, assistant_message_i = random.choice(
            assistant_messages[:-1]
        )  # do not choose the last one, since its meaningless to dependency
        real_content = assistant_message_i["content"]
        fake_contents = (
            list(
                set(
                    message["content"]
                    for _, message in assistant_messages
                    if message["content"] != real_content
                )
            )
            + [""]
            + [None]
        )
        fake_content = random.choice(fake_contents)
        fake_message_i = (
            {"role": "assistant", "content": fake_content, "learn": False}
            if fake_content is not None
            else None
        )
        if rand_bool():  # fix the wrong content at the next frame
            # case1: ... fake_message, frame, real_message, stream - 1 ...
            if (
                fake_message_i is not None
                and conversation[i + 1]["role"] == "stream"
                and conversation[i + 1]["num_frames"] > 1
            ):
                conversation = (
                    conversation[:i]
                    + [
                        fake_message_i,
                        {"role": "stream", "num_frames": 1, "learn": True},
                        {
                            "role": "assistant",
                            "content": f"(Sorry, the last response is wrong) {real_content}",
                            "learn": True,
                        },
                        {
                            "role": "stream",
                            "num_frames": conversation[i + 1]["num_frames"] - 1,
                            "learn": True,
                        },
                    ]
                    + conversation[i + 2 :]
                )
            # case2: ... stream + 1, real_message, stream -1, ...
            elif (
                fake_message_i is None
                and conversation[i - 1]["role"] == "stream"
                and conversation[i + 1]["role"] == "stream"
                and conversation[i + 1]["num_frames"] > 1
            ):
                conversation = (
                    conversation[: i - 1]
                    + [
                        {
                            "role": "stream",
                            "num_frames": conversation[i - 1]["num_frames"] + 1,
                            "learn": conversation[i - 1]["num_frames"] - 1,
                        },
                        {"role": "assistant", "content": real_content, "learn": True},
                        {
                            "role": "stream",
                            "num_frames": conversation[i + 1]["num_frames"] - 1,
                            "learn": True,
                        },
                    ]
                    + conversation[i + 2 :]
                )
        else:  # not fix
            # case3: ... fake_message, stream (unlearn) / message ...
            if fake_message_i is not None:
                if conversation[i + 1]["role"] == "stream":
                    conversation = (
                        conversation[:i]
                        + [
                            fake_message_i,
                            {
                                "role": "stream",
                                "num_frames": conversation[i + 1]["num_frames"],
                                "learn": False,
                            },
                        ]
                        + conversation[i + 2 :]
                    )
                else:
                    conversation = (
                        conversation[:i] + [fake_message_i] + conversation[i + 1 :]
                    )
            # case4: ... stream (learn-1), stream (unlearn) / message ...
            else:
                if conversation[i - 1]["role"] == "stream":
                    if conversation[i + 1]["role"] != "stream":
                        conversation = (
                            conversation[: i - 1]
                            + [
                                {
                                    "role": "stream",
                                    "num_frames": conversation[i - 1]["num_frames"],
                                    "learn": conversation[i - 1]["num_frames"] - 1,
                                },
                            ]
                            + conversation[i + 1 :]
                        )
                    else:
                        conversation = (
                            conversation[: i - 1]
                            + [
                                {
                                    "role": "stream",
                                    "num_frames": conversation[i - 1]["num_frames"]
                                    + conversation[i + 1]["num_frames"],
                                    "learn": conversation[i - 1]["num_frames"] - 1,
                                },
                            ]
                            + conversation[i + 2 :]
                        )
                else:
                    if conversation[i + 1]["role"] == "stream":
                        conversation = (
                            conversation[:i]
                            + [
                                {
                                    "role": "stream",
                                    "num_frames": conversation[i + 1]["num_frames"],
                                    "learn": False,
                                },
                            ]
                            + conversation[i + 2 :]
                        )
                    else:
                        conversation = conversation[:i] + conversation[i + 1 :]
        return conversation

    def max_frames_clip(
        self,
        conversation: list[dict],
        load_ranges: dict,
        max_num_frames: int,
    ):
        cum_num_frames = 0
        for i, message in enumerate(conversation):
            if message["role"] == "stream":
                if cum_num_frames + message["num_frames"] > max_num_frames:
                    conversation = conversation[:i]
                    load_ranges = {
                        path: ranger[:cum_num_frames]
                        for path, ranger in load_ranges.items()
                    }
                    break
                cum_num_frames += message["num_frames"]
        return conversation, load_ranges

    def __getitem__(
        self,
        *,
        conversation: list[dict],
        load_ranges: dict | torch.Tensor = None,
        bboxes: torch.Tensor = None,
        record=None,
        add_generation_prompt=False,
        **kwargs,
    ):
        if isinstance(load_ranges, torch.Tensor):
            frames = load_ranges
        elif load_ranges is not None:
            conversation, load_ranges = self.max_frames_clip(
                conversation, load_ranges, self.max_num_frames
            )
            frames = load_video(
                transform=self.transform,
                ranges=load_ranges,
                record=record,
            )
        else:
            frames = torch.tensor([])

        if self.augmentation: # default is false?
            conversation = self.augment(conversation)

        conversation = [
            {"role": "system", "content": self.system_prompt}
        ] + conversation

        # print("conversation in stream.py", conversation)

        text = self.tokenizer.apply_chat_template(
            conversation,
            tokenize=False,
            add_generation_prompt=add_generation_prompt,
        )
        '''
        before tokenizer: [{'role': 'system', 'content': 'You are a multimodal AI assistant that helps users with their daily activities. Below is your conversation with the user, interleaved with the list of video frames provided by the user.'}, {'role': 'user', 'content': 'Describe the activity step being performed in the video. Format your answer concisely. No extra text output.'}, {'role': 'stream', 'learn': True, 'num_frames': 8, 'long_context': ['']}, {'role': 'assistant', 'content': 'read the instructions', 'learn': True}]
        
        after tokenizer: User: Describe the activity step being performed in the video. Format your answer concisely. No extra text output. [<v><v><v><v><v>,<v><v><v><v><v>,<v><v><v><v><v>,<v><v><v><v><v>,<v><v><v><v><v>,<v><v><v><v><v>,<v><v><v><v><v>,<v><v><v><v><v>] Assistant: read the instructions<|eot_id|>
        '''
        if self.interleave: # shuffle interleave cache
            tokens = text.split("\n")
            interleave_cache = tokens[3]
            interleave_tokens = interleave_cache.split(',')
            interleave_tokens[0] = interleave_tokens[0][1:]
            interleave_tokens[-1] = interleave_tokens[-1][:-1]
            random.shuffle(interleave_tokens)
            interleave_cache = "[" + ",".join(interleave_tokens) + "]"
            text = tokens[0] + "\n\n" + tokens[2] + "\n" + interleave_cache + "\n" + tokens[4]
            

        learn_ranges = (
            self.tokenizer.get_learn_ranges(conversation)
            if not add_generation_prompt
            else []
        )

        return text, frames, learn_ranges, bboxes, load_ranges
